{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598764819414",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASX Tickers\n",
    "RAW_TICKER_ASX = pd.read_csv('https://www.asx.com.au/asx/research/ASXListedCompanies.csv',skiprows=1)\n",
    "RAW_TICKER_ASX[\"Ticker\"] = RAW_TICKER_ASX['ASX code']+\".AX\"\n",
    "TICKER_ASX = list(RAW_TICKER_ASX['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasdaq Tickers\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt\n",
    "\n",
    "RAW_TICKER_NDQ = pd.read_csv('/Users/JZ/Downloads/nasdaqlisted.txt',sep=\"|\")\n",
    "RAW_TICKER_NDQ[\"Ticker\"] = RAW_TICKER_NDQ['Symbol']\n",
    "TICKER_NDQ = list(RAW_TICKER_NDQ['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#London Stock Exchange Tickers\n",
    "RAW_TICKER_LSE = pd.read_excel (r'https://docs.londonstockexchange.com/sites/default/files/documents/list_of_sets_securities_14.xls', sheet_name='SETS',skiprows=3)\n",
    "RAW_TICKER_LSE[\"Ticker\"] = RAW_TICKER_LSE['Mnemonic']+\".L\"\n",
    "TICKER_LSE = list(RAW_TICKER_LSE['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NYSE Tickers\n",
    "#RAW_TICKER_NYSE = pd.read_excel (r'https://www.theice.com/publicdocs/data/NYSE_Equity_Index_Ticker_List.xlsx', sheet_name='SETS',skiprows=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append list for data extraction layer\n",
    "TICKER_ALL = (TICKER_ASX + TICKER_NDQ + TICKER_LSE)\n",
    "#Remove Duplicates\n",
    "TICKER_ALL = list(dict.fromkeys(TICKER_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample top 5 for testing code purposes\n",
    "TICKER_ASXs = TICKER_ASX[:5]\n",
    "TICKER_NDQs = TICKER_NDQ[:5]\n",
    "TICKER_LSEs = TICKER_LSE[:5]\n",
    "\n",
    "TICKER_ALL = (TICKER_ASXs + TICKER_NDQs + TICKER_LSEs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 1: Company Information\n",
    "\n",
    "INF_DF = pd.DataFrame()\n",
    "\n",
    "def Info_Extract(TickName):    \n",
    "    global INF_DF\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        INF = tick.info\n",
    "        INF_DF = INF_DF.append(INF, ignore_index=True) \n",
    "         \n",
    "        print(\"finished\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "    \n",
    "    return()\n",
    "\n",
    "#for company in ASX_TICKER_LIST:\n",
    "#    Info_Extract(company)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 2: financial data\n",
    "\n",
    "FINANCIALS_DF = pd.DataFrame()\n",
    "\n",
    "def Financials_Extract(TickName):\n",
    "    global FINANCIALS_DF\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        #income statement\n",
    "        FIN_OG = tick.financials\n",
    "        FIN_OG2 = FIN_OG.reset_index()\n",
    "        FIN_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        FIN_OG3=FIN_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        FIN_OG3['TickName']=TickName\n",
    "        FIN_OG3['Financial Data Type']=\"Income Statement\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(FIN_OG3, ignore_index=True)\n",
    "         \n",
    "        #balance sheet\n",
    "        BS_OG = tick.balance_sheet\n",
    "        BS_OG2 = BS_OG.reset_index()\n",
    "        BS_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        BS_OG3=BS_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        BS_OG3['TickName']=TickName\n",
    "        BS_OG3['Financial Data Type']=\"Balance Sheet\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(BS_OG3, ignore_index=True)\n",
    "        \n",
    "        #cashflow\n",
    "        CF_OG = tick.cashflow\n",
    "        CF_OG2 = CF_OG.reset_index()\n",
    "        CF_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        CF_OG3=CF_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        CF_OG3['TickName']=TickName\n",
    "        CF_OG3['Financial Data Type']=\"Cashflow\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(CF_OG3, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "#for company in TICKER_ALL:\n",
    "#    Financials_Extract(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 3: Download historical share prices\n",
    "\n",
    "HIST_PRICE_DF = pd.DataFrame()\n",
    "\n",
    "def Prices_Extract(TickName):\n",
    "    \n",
    "    global HIST_PRICE_DF\n",
    "\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        hist_p = tick.history(period=\"6mo\")\n",
    "        hist_p2 = hist_p.reset_index()\n",
    "        hist_p2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        \n",
    "        hist_p2['TickName']=TickName\n",
    "\n",
    "        HIST_PRICE_DF = HIST_PRICE_DF.append(hist_p2, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "#for company in TICKER_ALL:\n",
    "#    Prices_Extract(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: historical dividend information\n",
    "\n",
    "#DIV = tick.dividends  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "finished MOQ.AX\nfinished ONT.AX\nfinished 14D.AX\nfinished 1ST.AX\nfinished T3D.AX\nfinished AACG\nfinished AACQU\nfinished AAL\nfinished AAME\nfinished AAOI\nfinished DGE.L\nError with BA..L\nfinished BATS.L\nfinished IMB.L\nfinished HSBA.L\nfinished MOQ.AX\nfinished ONT.AX\nfinished 14D.AX\nfinished 1ST.AX\nfinished T3D.AX\nfinished AACG\nfinished AACQU\nfinished AAL\nfinished AAME\nfinished AAOI\nfinished DGE.L\nError with BA..L\nfinished BATS.L\nfinished IMB.L\nfinished HSBA.L\nfinished MOQ.AX\nfinished ONT.AX\nfinished 14D.AX\nfinished 1ST.AX\nfinished T3D.AX\nfinished AACG\nfinished AACQU\nfinished AAL\nfinished AAME\nfinished AAOI\nfinished DGE.L\n- BA..L: No data found, symbol may be delisted\nfinished BA..L\nfinished BATS.L\nfinished IMB.L\nfinished HSBA.L\n"
    }
   ],
   "source": [
    "# Export all 3 sections to excel\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Info_Extract(company)\n",
    "INF_DF.to_excel('/Users/JZ/Downloads/TEST_INFO.xlsx')\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Financials_Extract(company)\n",
    "FINANCIALS_DF.to_excel('/Users/JZ/Downloads/TEST_FIN.xlsx')\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Prices_Extract(company)\n",
    "HIST_PRICE_DF.to_excel('/Users/JZ/Downloads/TEST_Prices.xlsx')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# DF_SHORT =  INF_DF[INF_DF.columns[INF_DF.columns.isin(['longName','ask','52WeekChange'])]]\n",
    "\n",
    "DF_SHORT = INF_DF[['longName','ask']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<sqlite3.Cursor at 0x7fec61f543b0>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "#Need to add section for loading into sqlite database\n",
    "import sqlite3\n",
    "#create SQL datbase\n",
    "db_conn = sqlite3.connect(\"/Users/JZ/Downloads/Databases/test_database5.db\")\n",
    "c = db_conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "c.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE test (\n",
    "        ask INTEGER ,\n",
    "        longName TEXT NOT NULL,\n",
    "        PRIMARY KEY(ask)\n",
    "        );\n",
    "     \"\"\"\n",
    ")\n",
    "\n",
    "c.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE sales (\n",
    "        SalesID INTEGER ,\n",
    "        OrderID TEXT NOT NULL,\n",
    "        ProductID TEXT NOT NULL,\n",
    "        Sales REAL,\n",
    "        Quantity INTEGER,\n",
    "        Discount REAL,\n",
    "        Profit REAL,\n",
    "        PRIMARY KEY(SalesID),\n",
    "        FOREIGN KEY(OrderID) REFERENCES orders(OrderID),\n",
    "        FOREIGN KEY(ProductID) REFERENCES products(ProductID)\n",
    "        );\n",
    "     \"\"\"\n",
    ")\n",
    "\n",
    "#DF_SHORT.to_sql('test', db_conn, if_exists='append', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data\n",
    "DF_SHORT.to_sql('test', db_conn, if_exists='replace')\n",
    "\n",
    "#pd.read_sql('select * from INFO_SNAP', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    index                         longName       ask\n0       0                      MOQ Limited     0.150\n1       1               1300SMILES Limited     6.350\n2       2             1414 Degrees Limited     0.145\n3       3                1st Group Limited     0.033\n4       4                     333D Limited     0.002\n5       5            ATA Creativity Global     1.200\n6       6          Artius Acquisition Inc.    10.050\n7       7     American Airlines Group Inc.    13.570\n8       8    Atlantic American Corporation     2.100\n9       9    Applied Optoelectronics, Inc.    11.640\n10     10                       Diageo plc  2528.000\n11     11  British American Tobacco p.l.c.  2535.500\n12     12              Imperial Brands PLC  1263.500\n13     13                HSBC Holdings plc   330.950",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>longName</th>\n      <th>ask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>MOQ Limited</td>\n      <td>0.150</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>1300SMILES Limited</td>\n      <td>6.350</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>1414 Degrees Limited</td>\n      <td>0.145</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>1st Group Limited</td>\n      <td>0.033</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4</td>\n      <td>333D Limited</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>5</td>\n      <td>ATA Creativity Global</td>\n      <td>1.200</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>6</td>\n      <td>Artius Acquisition Inc.</td>\n      <td>10.050</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>7</td>\n      <td>American Airlines Group Inc.</td>\n      <td>13.570</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>8</td>\n      <td>Atlantic American Corporation</td>\n      <td>2.100</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>9</td>\n      <td>Applied Optoelectronics, Inc.</td>\n      <td>11.640</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>10</td>\n      <td>Diageo plc</td>\n      <td>2528.000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>11</td>\n      <td>British American Tobacco p.l.c.</td>\n      <td>2535.500</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>12</td>\n      <td>Imperial Brands PLC</td>\n      <td>1263.500</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>13</td>\n      <td>HSBC Holdings plc</td>\n      <td>330.950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "pd.read_sql('select * from test', db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}