{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598682147731",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASX Tickers\n",
    "RAW_TICKER_ASX = pd.read_csv('https://www.asx.com.au/asx/research/ASXListedCompanies.csv',skiprows=1)\n",
    "RAW_TICKER_ASX[\"Ticker\"] = RAW_TICKER_ASX['ASX code']+\".AX\"\n",
    "TICKER_ASX = list(RAW_TICKER_ASX['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasdaq Tickers\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt\n",
    "#ftp.nasdaqtrader.com/SymbolDirectory/otherlisted.txt\n",
    "\n",
    "RAW_TICKER_NDQ = pd.read_csv('/Users/JZ/Downloads/nasdaqlisted.txt',sep=\"|\")\n",
    "RAW_TICKER_NDQ[\"Ticker\"] = RAW_TICKER_NDQ['Symbol']\n",
    "TICKER_NDQ = list(RAW_TICKER_NDQ['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#London Stock Exchange Tickers\n",
    "RAW_TICKER_LSE = pd.read_excel (r'https://docs.londonstockexchange.com/sites/default/files/documents/list_of_sets_securities_14.xls', sheet_name='SETS',skiprows=3)\n",
    "RAW_TICKER_LSE[\"Ticker\"] = RAW_TICKER_LSE['Mnemonic']+\".L\"\n",
    "TICKER_LSE = list(RAW_TICKER_LSE['Ticker'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NYSE Tickers\n",
    "#RAW_TICKER_NYSE = pd.read_excel (r'https://www.theice.com/publicdocs/data/NYSE_Equity_Index_Ticker_List.xlsx', sheet_name='SETS',skiprows=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append list for data extraction layer\n",
    "TICKER_ALL = (TICKER_ASX + TICKER_NDQ + TICKER_LSE)\n",
    "#Remove Duplicates\n",
    "TICKER_ALL = list(dict.fromkeys(TICKER_ALL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download part 1: Company Information\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "company_df = pd.DataFrame()\n",
    "\n",
    "def Info_Extract(TickName):\n",
    "    \n",
    "    global company_df\n",
    "    \n",
    "    try:\n",
    "        tick = yf.Ticker(TickName)\n",
    "        filter_df = tick.info\n",
    "        company_df = company_df.append(filter_df, ignore_index=True) \n",
    "        print(\"Completed\",TickName)\n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Info_Extract(company)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download part 2: financial data\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "FINANCIALS_DF = pd.DataFrame()\n",
    "\n",
    "def Financials_Extract(TickName):\n",
    "    \n",
    "    global FINANCIALS_DF\n",
    "\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        #income statement\n",
    "        FIN_OG = tick.financials\n",
    "        FIN_OG2 = FIN_OG.reset_index()\n",
    "        FIN_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        FIN_OG3=FIN_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        FIN_OG3['TickName']=TickName\n",
    "        FIN_OG3['Financial Data Type']=\"Income Statement\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(FIN_OG3, ignore_index=True)\n",
    "         \n",
    "        #balance sheet\n",
    "        BS_OG = tick.balance_sheet\n",
    "        BS_OG2 = BS_OG.reset_index()\n",
    "        BS_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        BS_OG3=BS_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        BS_OG3['TickName']=TickName\n",
    "        BS_OG3['Financial Data Type']=\"Balance Sheet\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(BS_OG3, ignore_index=True)\n",
    "        \n",
    "        #cashflow\n",
    "        CF_OG = tick.cashflow\n",
    "        CF_OG2 = CF_OG.reset_index()\n",
    "        CF_OG2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        CF_OG3=CF_OG2.melt(id_vars=[\"Metric\"],var_name=\"Date\",value_name=\"Value\")\n",
    "        CF_OG3['TickName']=TickName\n",
    "        CF_OG3['Financial Data Type']=\"Cashflow\"\n",
    "        \n",
    "        FINANCIALS_DF = FINANCIALS_DF.append(CF_OG3, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Financials_Extract(company)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download part 3: Download historical share prices\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "HIST_PRICE_DF = pd.DataFrame()\n",
    "\n",
    "def Prices_Extract(TickName):\n",
    "    \n",
    "    global HIST_PRICE_DF\n",
    "\n",
    "    try:\n",
    "        tick = yf.Ticker(TickName) \n",
    "        \n",
    "        hist_p = tick.history(period=\"6mo\")\n",
    "        hist_p2 = hist_p.reset_index()\n",
    "        hist_p2.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "        \n",
    "        hist_p2['TickName']=TickName\n",
    "\n",
    "        HIST_PRICE_DF = HIST_PRICE_DF.append(hist_p2, ignore_index=True)\n",
    "        \n",
    "            \n",
    "        print(\"finished\",TickName)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error with\",TickName)\n",
    "        pass\n",
    "\n",
    "    return()\n",
    "\n",
    "\n",
    "for company in TICKER_ALL:\n",
    "    Prices_Extract(company)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all 3 sections to excel\n",
    "\n",
    "for company in ASX_TICKER_LIST:\n",
    "    Info_Extract(company)\n",
    "INF_DF.to_excel('/Users/JZ/Downloads/TEST_INFO.xlsx')\n",
    "\n",
    "\n",
    "for company in ASX_TICKER_LIST:\n",
    "    Financials_Extract(company)\n",
    "FINANCIALS_DF.to_excel('/Users/JZ/Downloads/TEST_FIN.xlsx')\n",
    "\n",
    "\n",
    "for company in ASX_TICKER_LIST:\n",
    "    Prices_Extract(company)\n",
    "HIST_PRICE_DF.to_excel('/Users/JZ/Downloads/TEST_Prices.xlsx')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Need to add section for loading into sqlite database"
   ]
  }
 ]
}